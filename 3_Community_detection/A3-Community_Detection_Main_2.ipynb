{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3. Community detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INFO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TASKS: \n",
    "\n",
    "\n",
    "[1] Apply at least three different community detection algorithms for the attached undirected networks\n",
    "\n",
    "[2] At least one of the algorithms must be based on the optimization of modularity\n",
    "\n",
    "[3] You must use at least two different programs\n",
    "\n",
    "#### Comparissons: \n",
    "[1] Partition of reference, obtained from external information. In these cases, you have to compare your partitions with them, using at least the following standard measures: Jaccard Index, Normalized Mutual Information (arithmetic normalization), and Normalized Variation of Information.\n",
    "\n",
    "#### DELIVERY\n",
    "[1] a plot with color-coded communities\n",
    "\n",
    "[2] Brief description of the algorithms and the programs used.\n",
    "\n",
    "[3] Selected parameters for each algorithm and/or network, and the scripts used (if any).\n",
    "\n",
    "[4] A table with the comparison measures between your partitions and the reference ones, grouped by network.\n",
    "\n",
    "[5] A table with the modularity values of all the partitions (including the reference ones), grouped by network.\n",
    "\n",
    "[6] The obtained partitions, in Pajek format (*.clu)\n",
    "\n",
    "\n",
    "\n",
    "#### CAVEATS: \n",
    "[1] The position of the nodes must not change for all the partitions of the same network.\n",
    "\n",
    "[2] If the network contains coordinates for the nodes (e.g. airports_UW.net), use them to establish the position of the nodes. Otherwise, use a layout algorithm to distribute the nodes in the plane trying to minimize the number of links crossings (e.g., Kamada-Kawai, ForceAtlas, etc.). Circular layouts must not be used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community \n",
    "\n",
    "- Groups of densely connected components in various networks. \n",
    "- Most widely used algorithm Girvan-Newman algorithm\n",
    "\n",
    "#### Techniques \n",
    "- **Agglomerative**: start only with the nodes of the original graph. Edges are added in a specific manner, if they have a weight, stronger ones are prioritized over weaker ones. \n",
    "\n",
    "- **Divisive**: Remove edges from the original graph iteratively. Stronger edges are removed before weaker ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the community module \n",
    "!pip3 install -qq python-louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## autoreload \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries \n",
    "import networkx as nx \n",
    "import matplotlib.pyplot as plt\n",
    "from community import community_louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper functions \n",
    "from src.helpers.community import NetworkXCommunityAlgs\n",
    "\n",
    "from src.helpers.helpers import read_clu,lol2idx,dict_vals_to_list,load_graph_coords\n",
    "from src.helpers.metrics import (nmi,\n",
    "                                 jaccard_index,\n",
    "                                 rand_index,\n",
    "                                 nvi_from_nmi)\n",
    "from src.helpers.plotters import plot_graph_partition_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Paths & Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper functions\n",
    "from src.helpers.config import config_dict,make_net_file_dict\n",
    "## Setting the PATHS to the specific directories \n",
    "DATA_DIR = './data'\n",
    "IMG_DIR = './imgs'\n",
    "## Loading the config dictionary \n",
    "CONFIG = config_dict(dir=DATA_DIR)\n",
    "## getting the net files & file dictionary\n",
    "NET_FILES, FILE_DICT = make_net_file_dict(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Original Graphs & Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some settings \n",
    "FIGURE_SIZE = (20,10)\n",
    "VISUALIZE = True        # change this if you want to visualize \n",
    "                        # the plots while they are being generated \n",
    "\n",
    "## these are plotted with NetworkX on matplotlib\n",
    "for net_type in FILE_DICT.keys():\n",
    "    plot_graph_partition_original(\n",
    "                                data        = FILE_DICT[net_type], \n",
    "                                net_type    = net_type,\n",
    "                                data_dir    = DATA_DIR,\n",
    "                                figure_size = FIGURE_SIZE,\n",
    "                                save_dir    = IMG_DIR,\n",
    "                                visualize   = VISUALIZE\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLOTTING THE ONES THAT DON'T WORK WITH iGraph\n",
    "import igraph as ig\n",
    "## Grid 6x6 \n",
    "dd = './data/toy/grid-p-6x6.net'\n",
    "save_dir = \"./imgs/toy/network_GRID_P_6x6_.png\"\n",
    "g = ig.read(dd)\n",
    "visual_style = {}\n",
    "visual_style[\"edge_width\"] = 0.05\n",
    "visual_style[\"vertex_size\"] = 3\n",
    "visual_style[\"bbox\"] = (300,300)\n",
    "visual_style[\"margin\"] = 10\n",
    "ig.plot(g, save_dir, **visual_style)\n",
    "\n",
    "## AIRPORTS UW\n",
    "## saving the AIRPORTS IMAGE \n",
    "dy = \"./data/real/airports_UW.net\"\n",
    "save_dir = \"./imgs/real/network_AIRPORTS_UW_.png\"\n",
    "g = ig.read(dy)\n",
    "visual_style = {}\n",
    "visual_style[\"edge_width\"] = 0.05\n",
    "visual_style[\"vertex_size\"] = 3\n",
    "visual_style[\"bbox\"] = (720,480)\n",
    "visual_style[\"margin\"] = 10\n",
    "ig.plot(g, save_dir, **visual_style)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Partitions for each graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_best_partition(graph):\n",
    "    ## \n",
    "    part = community.best_partition(graph)\n",
    "    ## communities\n",
    "    comms = [part.get(node) for node in graph.nodes()]\n",
    "    return comms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(data:list, community_alg:list):\n",
    "    \"\"\"Calculate NVI, NMI & Rand Index\"\"\"\n",
    "    import math\n",
    "    nvi = ig.compare_communities(data, community_alg,method='vi')/math.log(len(data))\n",
    "    nmi = ig.compare_communities(data, community_alg,method='nmi')\n",
    "    rand_idx = ig.compare_communities(data, community_alg, method='rand')\n",
    "    ## printmetrics rounded to 2 decimal places \n",
    "    #print(f\"| NVI: {round(nvi,2)} | NMI: {round(nmi,2)} | Rand Index: {round(rand_idx,2)}\")\n",
    "    return (nvi, nmi, rand_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_community(metrics: list) -> list:\n",
    "    tmp = metrics.copy()\n",
    "    for i,x in enumerate(tmp):\n",
    "        if type(x[0]) == dict:\n",
    "            tmp[i][0] = list(x[0].values())\n",
    "    return tmp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA = {\n",
    "                \"MODEL_TYPE\":None,\n",
    "                \"FILE_NAME\":None,\n",
    "                \"NUM_NODES\":None,\n",
    "                \"PARTITION_ID\":None,\n",
    "                \"METHOD\":None,\n",
    "                \"NUM_PARTITIONS\":None,\n",
    "                \"GEN_PARTITION\":None,\n",
    "                \"NVI\":None,\n",
    "                \"NMI\":None,\n",
    "                \"RAND_IDX\":None,\n",
    "                \"t1\":None,\n",
    "                \"t2\":None,\n",
    "                \"t3\":None\n",
    "            }\n",
    "\n",
    "def make_schema(SCHEMA, update_vals):\n",
    "    ### incoming vals are going to be the same as the schema \n",
    "    out = dict(zip(SCHEMA.keys(), update_vals))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [\"Garvin-Newman\",\"Asyn-Fluid\",\"Label-Propagation\",\"CN-Moore\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the above for loop into a function \n",
    "def get_payload(idx,alg,num_nodes,SCHEMA,MODEL, ofn, p_id,algorithms,v,HAS_ORIG_PART,t1,t2,t3,verbose=True):\n",
    "    ## calculate the metrics\n",
    "    print(len(data), len(alg[0]))\n",
    "    nvi, nmi, rand_idx = calculate_metrics(data = data, community_alg=alg[0])\n",
    "    payload = make_schema(SCHEMA,\n",
    "                            [MODEL, ofn,num_nodes, p_id,algorithms[idx],len(v),HAS_ORIG_PART, nmi, nvi, rand_idx,t1,t2,t3]\n",
    "                            )\n",
    "    ## if verbose \n",
    "    if verbose:\n",
    "        print(pd.DataFrame.from_records(payload, index=[0],columns=payload.keys()).to_markdown(),'\\n')\n",
    "    \n",
    "    return payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "## check if a file exists\n",
    "MODEL='toy'\n",
    "file_exists = os.path.isfile(f\"./data/model_metrics/{MODEL}.csv\")\n",
    "file_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os \n",
    "holder = []\n",
    "for MODEL in [\"toy\",\"model\",\"real\"]:\n",
    "    ## check if the file already exists in the folder \n",
    "    if os.path.isfile(f\"./data/model_metrics/{MODEL}.csv\"):\n",
    "        print(f\"{MODEL}.csv exists\")\n",
    "        continue\n",
    "    else:\n",
    "        for k, v in FILE_DICT[MODEL].items():\n",
    "            tic = time.time()\n",
    "            ofn = f\"{DATA_DIR}/{MODEL}/{k}.net\"\n",
    "            ## load the graph and position \n",
    "            g, pos = load_graph_coords(ofn) ## loading\n",
    "            num_nodes = len(g.nodes())\n",
    "            metrics = calculate_partitions(g, pos) ## communities\n",
    "            c_metrics = clean_community(metrics) ## cleaning\n",
    "            toc = time.time()\n",
    "            t1 = toc - tic\n",
    "            ## calculate the difference one ## original partition \n",
    "            if len(v) == 0: \n",
    "                data = make_best_partition(g)\n",
    "                p_id = 1\n",
    "                HAS_ORIG_PART = bool(False)\n",
    "            if len(v) ==1:\n",
    "                p_id = 1\n",
    "                data = read_clu(v[0])\n",
    "                HAS_ORIG_PART = bool(True)\n",
    "            for idx,alg in enumerate(c_metrics):\n",
    "                toc1 = time.time()\n",
    "                t2 = toc1 - toc\n",
    "                nvi, nmi, rand_idx = calculate_metrics(data = data, community_alg=alg[0])\n",
    "                payload = make_schema(\n",
    "                                    SCHEMA,\n",
    "                                    [MODEL, ofn,num_nodes, p_id,algorithms[idx],len(v),HAS_ORIG_PART, nmi, nvi, rand_idx,t1,t2]\n",
    "                                    )\n",
    "    \n",
    "                \n",
    "                holder.append(payload)\n",
    "            if len(v) > 1: \n",
    "                for idx, part in enumerate(v):\n",
    "                    ## pid\n",
    "                    p_id = idx + 1\n",
    "                    data = read_clu(part)\n",
    "                    HAS_ORIG_PART = bool(True)\n",
    "                    for nidx,alg in enumerate(c_metrics):\n",
    "                        print(len(data), len(alg[0]))\n",
    "                        nvi, nmi, rand_idx = calculate_metrics(data = data, community_alg=alg[0])\n",
    "                        payload = make_schema(\n",
    "                                                SCHEMA,\n",
    "                                                [MODEL, ofn,num_nodes, p_id,algorithms[idx],len(v),HAS_ORIG_PART, nmi, nvi, rand_idx,t1,t2]\n",
    "                                                )\n",
    "                        holder.append(payload)\n",
    "                        #print(pd.DataFrame.from_records(payload, index=[0],columns=payload.keys()).to_markdown(),'\\n')\n",
    "        ## save to dataframe\n",
    "        df = pd.DataFrame(holder)\n",
    "        df.to_csv(f\"./data/model_metrics/{MODEL}.csv\")\n",
    "        print(f\"{MODEL}.csv saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig \n",
    "from src.helpers.partitions import calculate_partitions\n",
    "import community \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "g, pos = load_graph_coords(ofn)\n",
    "metrics = calculate_partitions(g, pos)\n",
    "## clean the metrics \n",
    "c_metrics = clean_community(metrics)\n",
    "## print the metrics\n",
    "algorithms = [\"Girvan-Newman\",'Asyn-Fluid','Label-Prop','CN-Moore']\n",
    "for idx,alg in enumerate(c_metrics):\n",
    "    calculate_metrics(data = data, community_alg=alg[0], method_name=alg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## metrics \n",
    "\n",
    "import igraph as ig \n",
    "from src.helpers.partitions import calculate_partitions\n",
    "import community \n",
    "\n",
    "## calculate all the methods for a single network \n",
    "## load the graph \n",
    "model = 'model'\n",
    "name = 'rb125'\n",
    "sample = FILE_DICT[model][name]\n",
    "## original filename: DATA_DIR/model/name.net\n",
    "ofn = f\"{DATA_DIR}/{model}/{name}.net\"\n",
    "## load the graph and position \n",
    "g, pos = load_graph_coords(ofn)\n",
    "## calculate the difference one ## original partition \n",
    "first_partition= FILE_DICT[model][name][-1]\n",
    "data = read_clu(first_partition)\n",
    "## original filename: DATA_DIR/model/name.net\n",
    "ofn = f\"{DATA_DIR}/{model}/{name}.net\"\n",
    "## load the graph and position \n",
    "\n",
    "\n",
    "g, pos = load_graph_coords(ofn)\n",
    "metrics = calculate_partitions(g, pos)\n",
    "## clean the metrics \n",
    "c_metrics = clean_community(metrics)\n",
    "## print the metrics\n",
    "algorithms = [\"Girvan-Newman\",'Asyn-Fluid','Label-Prop','CN-Moore']\n",
    "for idx,alg in enumerate(c_metrics):\n",
    "    calculate_metrics(data = data, community_alg=alg[0], method_name=alg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_best_partition(graph):\n",
    "    ## \n",
    "    part = community.best_partition(graph)\n",
    "    ## communities\n",
    "    comms = [part.get(node) for node in graph.nodes()]\n",
    "    return comms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ## output dataframe |- MODEL_TYPE -|- MODEL_NAME -|- PARTITION -|- HAS_ORIG_PART -|- NMI -|- NVI -|- RIDX -|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA = {\n",
    "                \"MODEL_TYPE\":None,\n",
    "                \"FILE_NAME\":None,\n",
    "                \"NX_GRAPH\":None,\n",
    "                \"PART_ID\":None,\n",
    "                \"PART_ORIG\":None,\n",
    "                \"NVI\":None,\n",
    "                \"NMI\":None,\n",
    "                \"RAND_IDX\":None\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_schema(SCHEMA, update_vals):\n",
    "    ### incoming vals are going to be the same as the schema \n",
    "    out = dict(zip(SCHEMA.keys(), update_vals))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(data:list, community_alg:list,method:str):\n",
    "    \"\"\"Calculate NVI, NMI & Rand Index\"\"\"\n",
    "    import numpy as np\n",
    "    nvi = ig.compare_communities(data, community_alg,method='vi')/np.log(len(ca1_nc))\n",
    "    nmi = ig.compare_communities(data, community_alg,method='nmi')\n",
    "    rand_idx = ig.compare_communities(data, community_alg, method='rand')\n",
    "    ## printmetrics rounded to 2 decimal places \n",
    "    print(f\"METHOD: {method} | NVI: {round(nvi,2)} | NMI: {round(nmi,2)} | Rand Index: {round(rand_idx,2)}\")\n",
    "    return (nvi, nmi, rand_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALS = ['MODEL_TYPE', 'FILE_NAME', 'NX_GRAPH', 'PART_ID', 'PART_ORIG','METHOD','NVI','NMI','RAND_IDX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## all the models and their partitions, and if they dont have we generate one \n",
    "from collections import defaultdict\n",
    "from termcolor import colored \n",
    "from tqdm import tqdm\n",
    "verbosity = True\n",
    "schemas = []\n",
    "#model_partition = defaultdict(list)\n",
    "for model_type,models in FILE_DICT.items():\n",
    "    ## get the models and their partitions\n",
    "    for m,p in models.items():\n",
    "        L = len(p)\n",
    "        if \"airport\" in m: \n",
    "            pass\n",
    "        else: \n",
    "            ## there is no partition, create one using Louvain\n",
    "            # if verbosity:\n",
    "            #     txt1 = f\"Loading partition for {m}\"\n",
    "            #     print(txt1)\n",
    "            if L == 0:\n",
    "                # if verbosity:\n",
    "                #     txt2 = f\"--->[NP] Found no partition for {m}, generated using Louvain, added suffix _gen <--\"\n",
    "                #     print(colored(txt2, 'red'))\n",
    "                ## original file_name \n",
    "                ogfn = f\"{DATA_DIR}/{model_type}/{m}.net\"\n",
    "                print(ogfn,L)\n",
    "                ## load the graph\n",
    "                g, pos = load_graph_coords(ogfn)\n",
    "                partition = make_best_partition(g)\n",
    "                ## we calculate the partitions \n",
    "                print(\"Calculating Partitions\")\n",
    "                #ca1_nc, ca2_nc, ca3_nc, ca4_nc = calculate_partitions(g, pos)\n",
    "                community_partitions = calculate_partitions(g, pos)\n",
    "                c_cp = clean_community(community_partitions)\n",
    "                ## calculate the metrics for all of them\n",
    "                print(\"Getting Metrics\")\n",
    "                ## print the metrics\n",
    "                for idx,alg in enumerate(c_metrics):\n",
    "                    calculate_metrics(data = partition, community_alg=alg[0], method_name=alg[1])\n",
    "                        \n",
    "                ## we append the graph, the partition, and the partition name \n",
    "                ## calculate the partitions\n",
    "            ## only one partition: \n",
    "            if L == 1:\n",
    "                # if verbosity:\n",
    "                #     txt2 = f\"-->Found one partition for {m}<--\"\n",
    "                #     print(colored(txt2, 'green'))\n",
    "                ## reading the partition\n",
    "                partition = read_clu(p[0])\n",
    "                ogfn = f\"{DATA_DIR}/{model_type}/{m}.net\"\n",
    "                print(ogfn,L)\n",
    "                ## load the graph\n",
    "                g, pos = load_graph_coords(ogfn)\n",
    "                 ## we calculate the partitions \n",
    "                print(\"Calculating Partitions\")\n",
    "                #ca1_nc, ca2_nc, ca3_nc, ca4_nc = calculate_partitions(g, pos)\n",
    "                community_partitions = calculate_partitions(g, pos)\n",
    "                c_cp = clean_community(community_partitions)\n",
    "                ## calculate the metrics for all of them\n",
    "                print(\"Getting Metrics\")\n",
    "                ## print the metrics\n",
    "                for idx,alg in enumerate(c_metrics):\n",
    "                    calculate_metrics(data = data, community_alg=alg[0], method_name=alg[1])\n",
    "                \n",
    "            ## if it has more than one partition \n",
    "            if L > 1:\n",
    "                # if verbosity:\n",
    "                #     txt3 = f\"---> [MP] Found multiple partitions for {m}<-- added suffix _mult\"\n",
    "                #     print(colored(txt3, 'cyan'))\n",
    "                ## iterate over the partitions \n",
    "                multi_partition=dict()\n",
    "                ## assign\n",
    "                for ps in p:\n",
    "                    ## read the partition and assign it to the name \n",
    "                    multi_partition = read_clu(ps)\n",
    "                    ogfn = f\"{DATA_DIR}/{model_type}/{m}.net\"\n",
    "                    \n",
    "                    ## load the graph\n",
    "                    g, pos = load_graph_coords(ogfn)\n",
    "                    ## we calculate the partitions \n",
    "                    print(\"Calculating Partitions\")\n",
    "                    #ca1_nc, ca2_nc, ca3_nc, ca4_nc = calculate_partitions(g, pos)\n",
    "                    community_partitions = calculate_partitions(g, pos)\n",
    "                    ## calculate the metrics for all of them\n",
    "                    print(\"Getting Metrics\")\n",
    "                    c_cp = clean_community(community_partitions)\n",
    "                    ## calculate the metrics for all of them    \n",
    "                    for idx,alg in enumerate(c_metrics):\n",
    "                        calculate_metrics(data = data, community_alg=alg[0], method_name=alg[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REFERENCE CODE\n",
    "## calculate the difference one ## original partition \n",
    "#first_partition= FILE_DICT[model][name][-1]\n",
    "#data = read_clu(first_partition)\n",
    "## metrics \n",
    "\n",
    "import igraph as ig \n",
    "from src.helpers.partitions import calculate_partitions\n",
    "import community \n",
    "## original filename: DATA_DIR/model/name.net\n",
    "ofn = f\"{DATA_DIR}/{model}/{name}.net\"\n",
    "## load the graph and position \n",
    "g, pos = load_graph_coords(ofn)\n",
    "ca1_nc, ca2_nc, ca3_nc, ca4_nc = calculate_partitions(g, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculated algorithms\n",
    "#CAS = {ca1_nc, ca2_nc, ca3_nc, ca4_nc}\n",
    "## calculated communities\n",
    "## compare the metrics to the original one \n",
    "## original one:\n",
    "## original partition \n",
    "first_partition= FILE_DICT[model][name][-1]\n",
    "data = read_clu(first_partition)\n",
    "\n",
    "\n",
    "## plot with original partitions \n",
    "nx.draw(g, pos=pos, node_color=data, with_labels=True)\n",
    "plt.show()\n",
    "## get the calculated partition \n",
    "ca1_nc1 = [x+1 for x in ca1_nc]\n",
    "nx.draw(g, pos=pos, node_color=ca1_nc1, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## original partition \n",
    "first_partition= FILE_DICT[model][name][-1]\n",
    "data = read_clu(first_partition)\n",
    "\n",
    "## plot with original partitions \n",
    "nx.draw(g, pos=pos, node_color=data, with_labels=True)\n",
    "plt.show()\n",
    "## get the calculated partition \n",
    "ca1_nc1 = [x+1 for x in ca1_nc]\n",
    "nx.draw(g, pos=pos, node_color=ca1_nc1, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## partition names \n",
    "## get the reference partition\n",
    "clu = [read_clu(x) for x in sample]\n",
    "## individual clu files \n",
    "c1, c2, c3 = clu\n",
    "## c1-c3 are original ones \n",
    "## received partition is ca1_c\n",
    "assert len(c1) == len(ca1_nc)\n",
    "print(\"Equal\")\n",
    "## calculate a metric \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculate a metric \n",
    "from igraph import compare_communities as cm\n",
    "import math\n",
    "## N is the number of nodes\n",
    "num_nodes = len(g.nodes())\n",
    "nvi = cm(c1, ca1_nc, method='vi')/math.log(num_nodes)   # Normalized Variation of Information\n",
    "nmi = cm(c1, ca1_nc, method='nmi') \n",
    "ri = cm(c1, ca1_nc, method='rand')\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(g,pos=pos, node_color=ca1_nc, node_size=15, alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (12,8)\n",
    "## get a single model with its partitions \n",
    "net_type = 'toy'\n",
    "model_name = 'graph3+1+3'\n",
    "## original directory \n",
    "og_dir = f\"{DATA_DIR}/{net_type}/{model_name}.net\"\n",
    "## load the graph and the position \n",
    "g, pos = load_graph_coords(file_path = og_dir)\n",
    "## read the clu file \n",
    "clu_file = FILE_DICT[net_type][model_name][0]\n",
    "cl = dict(read_clu(clu_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## iterate over the model types \n",
    "for net_type,networks in FILE_DICT.items():\n",
    "    ## iterate over the networks \n",
    "    for graph, partition in networks.items():\n",
    "        ## original directory \n",
    "        og_dir = f\"{DATA_DIR}/{net_type}/{graph}.net\"\n",
    "        ## load the graph and the position \n",
    "        g, pos = load_graph_coords(file_path = og_dir)\n",
    "        ## get the length of the partition \n",
    "        psize = len(partition)\n",
    "        ## if it only has one partition\n",
    "        if psize==1: \n",
    "            ## load the only partition \n",
    "            clu_file = partition[0]\n",
    "            cl = dict(read_clu(clu_file))\n",
    "            ## we plot the 1x5 graph (original + 4x methods)\n",
    "            ## if there are multiple partitions, get the corresponding one and plot them \n",
    "            fig, axs = plt.subplots(1, 5, figsize=(20,8)) ## maybe change to 2x3 lets see.\n",
    "            axs = axs.ravel()\n",
    "            ## plot 1: Original Partition \n",
    "            nx.draw(g,pos=pos, ax=axs[0], node_color=list(cl.values()), node_size=15, alpha=0.9)\n",
    "            axs[0].set_title(f\"Number of Communities: {len(set([x for x in cl.values()]))}\")\n",
    "\n",
    "            ## PARTITION 1: NEWMAN\n",
    "            ca1 = NetworkXCommunityAlgs(g, method='girvan_newman',layout=pos, verbosity=False)\n",
    "            ca1_comm, ca1_nc = ca1.algorithm\n",
    "            nx.draw(g,pos=pos, node_color=dict_vals_to_list(ca1_nc[0]), node_size=15, alpha=0.9,ax=axs[1])\n",
    "            axs[1].set_title(f\"{ca1.method.upper()} | Communities: {len(set([x for x in ca1_nc[0].values()]))}\")\n",
    "\n",
    "            ## plot the method 2: ASYN_FLUID: PARAMETERS: k=5, max_iter=100\n",
    "            params = {'_k':5, '_max_iter':100}\n",
    "            ca2 = NetworkXCommunityAlgs(g, method='asyn_fluid',layout=pos, verbosity=False, params=params)\n",
    "            ca2_comm, ca2_nc = ca2.algorithm\n",
    "            nx.draw(g,pos=pos, ax=axs[2], node_color=dict_vals_to_list(ca2_nc), node_size=15, alpha=0.9)\n",
    "            axs[2].set_title(f\"{ca2.method.upper()} | Communities: {len(set([x for x in ca2_nc.values()]))}\")\n",
    "\n",
    "            ## plotting the method 3: Label Propagation\n",
    "            ca3 = NetworkXCommunityAlgs(g, method='label_prop',layout=pos, verbosity=False)\n",
    "            ca3_comm, ca3_nc = ca2.algorithm\n",
    "            nx.draw(g,pos=pos, ax=axs[3], node_color=dict_vals_to_list(ca3_nc), node_size=15, alpha=0.9)\n",
    "            axs[3].set_title(f\"{ca3.method.upper()} | Communities: {len(set([x for x in ca3_nc.values()]))}\")\n",
    "\n",
    "            ## plotting the method 4: CN-Moore  \n",
    "            params = {'n_comm':3} ## number of communities \n",
    "            ca4 = NetworkXCommunityAlgs(g, method='cn_moore',layout=pos, verbosity=False, params=params)\n",
    "            ca4_comm, ca4_nc = ca4.algorithm\n",
    "            nx.draw(g,pos=pos, ax=axs[4], node_color=dict_vals_to_list(ca4_nc), node_size=15, alpha=0.9)\n",
    "            axs[4].set_title(f\"{ca4.method.upper()} | Communities: {len(set([x for x in ca4_nc.values()]))}\")\n",
    "\n",
    "        plt.show()\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## if there are multiple partitions, get the corresponding one and plot them \n",
    "fig, axs = plt.subplots(1, 5, figsize=(20,8))\n",
    "axs = axs.ravel()\n",
    "## plot 1: Original Partition \n",
    "nx.draw(g,pos=pos, ax=axs[0], node_color=list(cl.values()), node_size=15, alpha=0.9)\n",
    "axs[0].set_title(f\"Number of Communities: {len(set([x for x in cl.values()]))}\")\n",
    "\n",
    "## PARTITION 1: NEWMAN\n",
    "ca1 = NetworkXCommunityAlgs(g, method='girvan_newman',layout=pos, verbosity=False)\n",
    "ca1_comm, ca1_nc = ca1.algorithm\n",
    "nx.draw(g,pos=pos, node_color=dict_vals_to_list(ca1_nc[0]), node_size=15, alpha=0.9,ax=axs[1])\n",
    "axs[1].set_title(f\"{ca1.method.upper()} | Communities: {len(set([x for x in ca1_nc[0].values()]))}\")\n",
    "\n",
    "## plot the method 2: ASYN_FLUID: PARAMETERS: k=5, max_iter=100\n",
    "params = {'_k':5, '_max_iter':100}\n",
    "ca2 = NetworkXCommunityAlgs(g, method='asyn_fluid',layout=pos, verbosity=False, params=params)\n",
    "ca2_comm, ca2_nc = ca2.algorithm\n",
    "nx.draw(g,pos=pos, ax=axs[2], node_color=dict_vals_to_list(ca2_nc), node_size=15, alpha=0.9)\n",
    "axs[2].set_title(f\"{ca2.method.upper()} | Communities: {len(set([x for x in ca2_nc.values()]))}\")\n",
    "\n",
    "## plotting the method 3: Label Propagation\n",
    "ca3 = NetworkXCommunityAlgs(g, method='label_prop',layout=pos, verbosity=False)\n",
    "ca3_comm, ca3_nc = ca2.algorithm\n",
    "nx.draw(g,pos=pos, ax=axs[3], node_color=dict_vals_to_list(ca3_nc), node_size=15, alpha=0.9)\n",
    "axs[3].set_title(f\"{ca3.method.upper()} | Communities: {len(set([x for x in ca3_nc.values()]))}\")\n",
    "\n",
    "## plotting the method 4: CN-Moore  \n",
    "params = {'n_comm':3} ## number of communities \n",
    "ca4 = NetworkXCommunityAlgs(g, method='cn_moore',layout=pos, verbosity=False, params=params)\n",
    "ca4_comm, ca4_nc = ca4.algorithm\n",
    "nx.draw(g,pos=pos, ax=axs[4], node_color=dict_vals_to_list(ca4_nc), node_size=15, alpha=0.9)\n",
    "axs[4].set_title(f\"{ca4.method.upper()} | Communities: {len(set([x for x in ca4_nc.values()]))}\")\n",
    "\n",
    "## showing\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import community \n",
    "## import the colored module \n",
    "from termcolor import colored\n",
    "def make_best_partition(graph):\n",
    "    ## \n",
    "    part = community.best_partition(graph)\n",
    "    ## communities\n",
    "    comms = [part.get(node) for node in graph.nodes()]\n",
    "    return comms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## iterate over the networks and get their corresponding partitions \n",
    "## except AIRPORTS & Grid 6x6\n",
    "save_dir = \"./imgs/partitions/\"\n",
    "## test a single model \n",
    "net_type = 'toy'\n",
    "tst = FILE_DICT[net_type]\n",
    "## original path \n",
    "#og_dir = f\"{DATA_DIR}/{net_type}/{k}.net\"\n",
    "for model,partitions in tst.items():\n",
    "    og_dir = f\"{DATA_DIR}/{net_type}/{model}.net\"\n",
    "    ## load the original graph \n",
    "    g, pos = load_graph_coords(file_path = og_dir)\n",
    "    ## define the subplots \n",
    "    fig, axs = plt.subplots(1,4)\n",
    "    axs = axs.ravel()\n",
    "    ## load the partitions\n",
    "    for idx,parts in enumerate(partitions):\n",
    "        ## read the partition file \n",
    "        cl = dict(read_clu(parts))\n",
    "        ## plot the partition method 1: Girvan-Newman\n",
    "        ca1 = NetworkXCommunityAlgs(g, method='girvan_newman',layout=pos, verbosity=False)\n",
    "        ca1_comm, ca1_nc = ca1.algorithm\n",
    "        nx.draw(g,pos=pos, ax=axs[idx], node_color=dict_vals_to_list(ca1_nc[0]), node_size=15, alpha=0.9)\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## iterate through the DATA dictionary and plot the graph and its corresponding partition\n",
    "for model_type, netpart in FILE_DICT.items():\n",
    "    ## iterate through each of the netpart files; tuples (.net, .clu)\n",
    "    ## create the figure MODELS x PARTITIONS\n",
    "    fig, axs = plt.subplots(len(FILE_DICT[model_type])+1, 2+4, figsize=(20,10),sharex=True, sharey=True)\n",
    "    #axs = axs.ravel()\n",
    "    for idx,pairs in enumerate(netpart): \n",
    "        _net, _clu = pairs #separate them\n",
    "        net_name = _net.split(\"/\")[-1].split(\".\")[0]\n",
    "        g, pos = load_graph_coords(_net) # load the graph and layout\n",
    "        cl = dict(read_clu(_clu)) # original partition \n",
    "        ## plot the original \n",
    "        nx.draw(g,pos=pos, ax=axs[idx,0], node_size=15, alpha=0.9)\n",
    "        ## plot the partition\n",
    "        nx.draw(g,pos=pos, ax=axs[idx,1], node_color=list(cl.values()), node_size=15, alpha=0.9)\n",
    "        ## plot the partition method 1: Girvan-Newman\n",
    "        ca1 = NetworkXCommunityAlgs(g, method='girvan_newman',layout=pos, verbosity=False)\n",
    "        ca1_comm, ca1_nc = ca1.algorithm\n",
    "        nx.draw(g,pos=pos, ax=axs[idx,2], node_color=dict_vals_to_list(ca1_nc[0]), node_size=15, alpha=0.9)\n",
    "        ## plot the method 2: ASYN_FLUID: PARAMETERS: k=5, max_iter=100\n",
    "        params = {'_k':5, '_max_iter':100}\n",
    "        ca2 = NetworkXCommunityAlgs(g, method='asyn_fluid',layout=pos, verbosity=False, params=params)\n",
    "        ca2_comm, ca2_nc = ca2.algorithm\n",
    "        nx.draw(g,pos=pos, ax=axs[idx,3], node_color=dict_vals_to_list(ca2_nc), node_size=15, alpha=0.9)\n",
    "        ## plotting the method 3: Label Propagation\n",
    "        ca3 = NetworkXCommunityAlgs(g, method='label_prop',layout=pos, verbosity=False)\n",
    "        ca3_comm, ca3_nc = ca2.algorithm\n",
    "        nx.draw(g,pos=pos, ax=axs[idx,4], node_color=dict_vals_to_list(ca3_nc), node_size=15, alpha=0.9)\n",
    "        ## plotting the method 4: CN-Moore  \n",
    "        params = {'n_comm':3} ## number of communities \n",
    "        ca4 = NetworkXCommunityAlgs(g, method='cn_moore',layout=pos, verbosity=False, params=params)\n",
    "        ca4_comm, ca4_nc = ca4.algorithm\n",
    "        nx.draw(g,pos=pos, ax=axs[idx,5], node_color=dict_vals_to_list(ca4_nc), node_size=15, alpha=0.9)\n",
    "        ## set the titles\n",
    "        axs[idx,0].set_title(f'NET: {net_name}')\n",
    "        axs[idx,1].set_title('Original Partition')\n",
    "        axs[idx,2].set_title('Partition 1: Girvan-Newman')\n",
    "        axs[idx,3].set_title('Partition 2: Asynchronous-Fluid')\n",
    "        axs[idx,4].set_title('Partition 3: Label Propagation')\n",
    "        axs[idx,5].set_title('Partition 4: CN-Moore')\n",
    "    plt.suptitle(f'Model: {model_type}', fontsize=20, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(\"figures/{}.png\".format(model_type), bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing iGraph Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 100, 100\n",
    "g = ig.read(dy)\n",
    "## try to use the same methods we used \n",
    "## MODULARITY \n",
    "dendrogram = g.community_fastgreedy()\n",
    "clusters = dendrogram.as_clustering()\n",
    "membership = clusters.membership\n",
    "## dictionary \n",
    "d = dict(zip(g.vs['name'],membership))\n",
    "## plotting the colors\n",
    "pal = ig.drawing.colors.ClusterColoringPalette(len(clusters))\n",
    "g.vs['color'] = pal.get_many(clusters.membership)\n",
    "\n",
    "visual_style = {}\n",
    "visual_style[\"edge_width\"] = 0.05\n",
    "visual_style[\"vertex_size\"] = 3\n",
    "visual_style[\"bbox\"] = (1920,1024)\n",
    "visual_style[\"margin\"] = 10\n",
    "#ig.plot(g, **visual_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the net and clu files\n",
    "#g = nx.read_pajek(net)\n",
    "g, pos = load_graph_coords(net)\n",
    "cl = dict(read_clu(clu))\n",
    "\n",
    "## plotting \n",
    "## create the figure \n",
    "fig, axs = plt.subplots(1, 2+NUM_PARTITIONS, figsize=(20,5))\n",
    "axs = axs.ravel()\n",
    "## plot the original \n",
    "nx.draw(g,pos=pos, ax=axs[0], node_size=15, alpha=0.9)\n",
    "\n",
    "## plot the partition\n",
    "nx.draw(g,pos=pos, ax=axs[1], node_color=list(cl.values()), node_size=15, alpha=0.9)\n",
    "\n",
    "\n",
    "## plot the partition method 1: Girvan-Newman\n",
    "ca1 = NetworkXCommunityAlgs(g, method='girvan_newman',layout=nx.kamada_kawai_layout(g), verbosity=False)\n",
    "ca1_comm, ca1_nc = ca1.algorithm\n",
    "nx.draw(g,pos=pos, ax=axs[2], node_color=dict_vals_to_list(ca1_nc[0]), node_size=15, alpha=0.9)\n",
    "\n",
    "\n",
    "## plot the method 2: ASYN_FLUID: PARAMETERS: k=5, max_iter=100\n",
    "params = {'_k':5, '_max_iter':100}\n",
    "ca2 = NetworkXCommunityAlgs(g, method='asyn_fluid',layout=nx.kamada_kawai_layout(g), verbosity=False, params=params)\n",
    "ca2_comm, ca2_nc = ca2.algorithm\n",
    "nx.draw(g,pos=pos, ax=axs[3], node_color=dict_vals_to_list(ca2_nc), node_size=15, alpha=0.9)\n",
    "\n",
    "## plotting the method 3: Label Propagation\n",
    "ca3 = NetworkXCommunityAlgs(g, method='label_prop',layout=nx.kamada_kawai_layout(g), verbosity=False)\n",
    "ca3_comm, ca3_nc = ca2.algorithm\n",
    "nx.draw(g,pos=pos, ax=axs[4], node_color=dict_vals_to_list(ca3_nc), node_size=15, alpha=0.9)\n",
    "\n",
    "## plotting the method 4: CN-Moore\n",
    "params = {'n_comm':3} ## number of communities \n",
    "ca4 = NetworkXCommunityAlgs(g, method='cn_moore',layout=nx.kamada_kawai_layout(g), verbosity=False, params=params)\n",
    "ca4_comm, ca4_nc = ca4.algorithm\n",
    "nx.draw(g,pos=pos, ax=axs[5], node_color=dict_vals_to_list(ca4_nc), node_size=15, alpha=0.9)\n",
    "\n",
    "## set the titles \n",
    "axs[0].set_title('Original')\n",
    "axs[1].set_title('Partition')\n",
    "axs[2].set_title('Partition 1: Girvan-Newman')\n",
    "axs[3].set_title('Partition 2: Asynchronous-Fluid')\n",
    "axs[4].set_title('Partition 3: Label Propagation')\n",
    "axs[5].set_title('Partition 4: CN-Moore')\n",
    "\n",
    "plt.suptitle(f'Toy Example: {net.split(\"/\")[-1]}', fontsize=20, y=1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iGraph Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig \n",
    "## load the sample \n",
    "g = ig.read(net)\n",
    "## try to use the same methods we used \n",
    "## MODULARITY \n",
    "dendrogram = g.community_fastgreedy()\n",
    "clusters = dendrogram.as_clustering()\n",
    "membership = clusters.membership\n",
    "## dictionary \n",
    "d = dict(zip(g.vs['name'],membership))\n",
    "## plotting the colors\n",
    "pal = ig.drawing.colors.ClusterColoringPalette(len(clusters))\n",
    "g.vs['color'] = pal.get_many(clusters.membership)\n",
    "ig.plot(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LABEL PROPAGATION \n",
    "lp = g.community_label_propagation()\n",
    "lp_mem = lp.membership\n",
    "## dictionary\n",
    "dlp = dict(zip(g.vs['name'],lp_mem))\n",
    "lp_pal = ig.drawing.colors.ClusterColoringPalette(len(lp))\n",
    "g.vs['color'] = lp_pal.get_many(lp.membership)\n",
    "ig.plot(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GIRVAB-NEWMAN\n",
    "gn = g.community_leading_eigenvector()\n",
    "gn_mem = lp.membership\n",
    "## dictionary\n",
    "dlp = dict(zip(g.vs['name'],gn_mem))\n",
    "gn_pal = ig.drawing.colors.ClusterColoringPalette(len(gn))\n",
    "g.vs['color'] = gn_pal.get_many(gn.membership)\n",
    "ig.plot(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This works to plot the different k-communities in a graph \n",
    "from networkx.algorithms.community.centrality import girvan_newman\n",
    "mapper = {name:idx for idx, name in  enumerate(ga.nodes())}\n",
    "## apply the algorithm to the graph \n",
    "communities = girvan_newman(ga) ## generator object\n",
    "## another approach to get the community\n",
    "pos = nx.fruchterman_reingold_layout(ga)\n",
    "import itertools \n",
    "## define the number of communities (tuple)\n",
    "k = 6\n",
    "fig, axs = plt.subplots(1, k, figsize=(20,5))\n",
    "axs = axs.ravel()\n",
    "for idx, comm in enumerate(itertools.islice(communities, k)):\n",
    "    part = tuple(sorted(c) for c in comm)\n",
    "    b = lol2idx(part) ## Converts the list of list into a dictionary of sublist-index \n",
    "    nx.draw(ga,pos=pos, node_color=list(b.values()), node_size=15, ax=axs[idx])#,with_labels=True)\n",
    "    axs[idx].set_title(f\"Partition k={idx+1}\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NetworkX Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Community Detection Algorithm 1: Girvan-Newman algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.centrality.girvan_newman.html#networkx.algorithms.community.centrality.girvan_newman\n",
    "\n",
    "- Divisive method, progressively removes edges from the original graph. \n",
    "- Removes the \"most-valuable\" edge. \n",
    "    - Highest betweenness centrality.\n",
    "        - Highest number of shortest paths between nodes. \n",
    "        - definition is unclear but something as: \n",
    "            Number of shortest paths through V or E / Total shortest paths\n",
    "- Result can be shown as a dendrogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply the algorithm to the graph \n",
    "communities = girvan_newman(g) ## generator object \n",
    "## get the nodes belonging to the first community\n",
    "node_groups = [com for com in next(communities)]\n",
    "## loop over the nodes in the original graph \n",
    "## if they are the original assign a color to them\n",
    "c1 = 'red'\n",
    "c2 = 'blue'\n",
    "color_map = [c2 if node in node_groups[0] else c1  for node in g.nodes()]\n",
    "## draw it again \n",
    "nx.draw(g, node_color=color_map, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx.algorithms.community as nx_comm\n",
    "nx_comm.modularity(g, node_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## another approach to get the community\n",
    "import itertools \n",
    "## define the number of communities (tuple)\n",
    "k = 5\n",
    "for comm in itertools.islice(communities, k):\n",
    "    print(tuple(sorted(c) for c in comm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using another package \n",
    "from community import community_louvain\n",
    "import community\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# compute the best partition\n",
    "partition = community_louvain.best_partition(g)\n",
    "print(partition)\n",
    "# draw the graph\n",
    "pos = nx.spring_layout(g)\n",
    "# color the nodes according to their partition\n",
    "cmap = cm.get_cmap('tab10', max(partition.values()) + 1)\n",
    "## draw the nodes\n",
    "nx.draw_networkx_nodes(g, pos, partition.keys(), node_size=40,\n",
    "                       cmap=cmap, node_color=list(partition.values()))\n",
    "## draw the edges \n",
    "nx.draw_networkx_edges(g, pos, alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## given two sets of partitions or communities, calculate the metrics\n",
    "\n",
    "## community 1 \n",
    "l1 = sorted(partition.values(),reverse=False)\n",
    "## community 2 \n",
    "l2 = [1,1,1,1,2,2,2,2]\n",
    "## normalized mutual information\n",
    "_nmi = nmi(l1,l2)\n",
    "## jaccard index \n",
    "jac_idx = jaccard_index(l1,l2)\n",
    "## randindex \n",
    "rand_id = rand_index(l1,l2)\n",
    "## nvi = normalized variation of information\n",
    "_nvi = nvi_from_nmi(l1,l2,len(l1))\n",
    "\n",
    "## feedback \n",
    "print(f\"NMI: {_nmi:.2f}\")\n",
    "print(f\"Jaccard index: {jac_idx:.2f}\")\n",
    "print(f\"Rand index: {rand_id:.2f}\")\n",
    "print(f\"NVI: {_nvi:.2f}\")\n",
    "tracker_metrics = {'nmi':_nmi,\n",
    "                   'jaccard_index':jac_idx,\n",
    "                   'rand_index':rand_id,\n",
    "                   'nvi':_nvi}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = community.best_partition(g)\n",
    "pos = nx.spring_layout(g)\n",
    "nx.draw_networkx_nodes(g, pos, node_color=list(partition.values))\n",
    "nx.draw_networkx_edges(g,pos,alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Community Detection Algorithm 2: Fluid Communities algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.centrality.girvan_newman.html#networkx.algorithms.community.centrality.girvan_newman\n",
    "\n",
    "\n",
    "Very nice graphs \n",
    "https://arxiv.org/pdf/1703.09307.pdf\n",
    "\n",
    "- Based on \"fluids interacting with each other\" \n",
    "    - expanding and pushing each other. \n",
    "\n",
    "Mechanics: \n",
    "- Initial k communities initialized on a random vertex. \n",
    "- Iterate over all vertices in random order. \n",
    "- **Vertex move from one place to the other, different densities, shifts**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import \n",
    "from networkx.algorithms.community import asyn_fluid\n",
    "## set parameters \n",
    "## K is the number of communities\n",
    "K = 6\n",
    "## max_iter is the maximum number of iterations\n",
    "max_iter = 100\n",
    "## assign fluids \n",
    "fluids = asyn_fluid.asyn_fluidc(G=g, k=K, max_iter=max_iter)\n",
    "## iterate over the fluids and print the communities\n",
    "cmms = [fluid for fluid in fluids]\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(3,2, figsize=(20,10))\n",
    "axs = axs.ravel()\n",
    "## assign a color to each community\n",
    "for idx, i in enumerate(cmms):\n",
    "    color_map = [c2 if node in cmms[idx] else c1  for node in g.nodes()]     \n",
    "    ## drawing the graph\n",
    "    nx.draw(g, node_color=color_map, with_labels=True, ax=axs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,2, figsize=(20,10))\n",
    "axs = axs.ravel()\n",
    "for idx, K in enumerate(range(1,len(g.edges()),1)):\n",
    "    fluids = asyn_fluid.asyn_fluidc(G=g, k=K, max_iter=max_iter)\n",
    "    l = [fluid for fluid in fluids]\n",
    "    cy = lol2idx(l)\n",
    "    cd = dict_vals_to_list(cy)\n",
    "    nx.draw(g, node_color=cd, with_labels=True, ax=axs[idx])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Community Detection Algorithm 3: Label Propagation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.community import label_propagation\n",
    "#compute the communities\n",
    "communities = label_propagation.label_propagation_communities(g)\n",
    "nc = lol2idx(communities)\n",
    "nx.draw(g, node_color=dict_vals_to_list(nc), with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Community Detection Algorithm 4: Clique Percolation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.community import k_clique_communities\n",
    "## define k\n",
    "k = 2\n",
    "comms = list(k_clique_communities(g,k))\n",
    "nc = lol2idx(comms)\n",
    "nx.draw(g, node_color=dict_vals_to_list(nc), with_labels=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac6858c3dbc49267e902ff986705b591b9d7b57befff84fd7d814fe16c4a8e1f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
