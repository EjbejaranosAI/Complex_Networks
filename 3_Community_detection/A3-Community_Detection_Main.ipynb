{"cells":[{"cell_type":"markdown","metadata":{"id":"BxJ2GIdNFJUo"},"source":["## A3. Community detection"]},{"cell_type":"markdown","metadata":{"id":"S5hNC3P2FJU4"},"source":["### Imports & Settings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S_6ZzGRcFJU6"},"outputs":[],"source":["## get the community module \n","!pip3 install -qq python-louvain\n","!pip3 install -qq networkx"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NVNgAy_PFJU9"},"outputs":[],"source":["## autoreload \n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"dxKpCs5DFJU-"},"source":["### Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sdrF05FgFO_W"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kOs8R7mMFdWs"},"outputs":[],"source":["## change to the work dir \n","WORK_DIR = \"./drive/MyDrive/Cursos/3_Community_detection\"\n","import os; os.chdir(WORK_DIR)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UkBTmQ19FJU_"},"outputs":[],"source":["## import libraries \n","import networkx as nx \n","import matplotlib.pyplot as plt\n","from community import community_louvain"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OVFZbZIvFJVA"},"outputs":[],"source":["## helper functions \n","from src.helpers.community import NetworkXCommunityAlgs\n","\n","from src.helpers.helpers import read_clu,lol2idx,dict_vals_to_list,load_graph_coords\n","from src.helpers.metrics import (nmi,\n","                                 jaccard_index,\n","                                 rand_index,\n","                                 nvi_from_nmi)\n","from src.helpers.plotters import plot_graph_partition_original"]},{"cell_type":"markdown","metadata":{"id":"4iQnWk-mFJVB"},"source":["### Defining Paths & Variables"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q7OcKAbHFJVC"},"outputs":[],"source":["## helper functions\n","from src.helpers.config import config_dict,make_net_file_dict\n","## Setting the PATHS to the specific directories \n","DATA_DIR = './data'\n","IMG_DIR = './imgs'\n","## Loading the config dictionary \n","CONFIG = config_dict(dir=DATA_DIR)\n","## getting the net files & file dictionary\n","NET_FILES, FILE_DICT = make_net_file_dict(CONFIG)"]},{"cell_type":"markdown","metadata":{"id":"FltsXwxWFJVD"},"source":["### Plotting Original Graphs & Partitions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c9R9WGe0FJVE"},"outputs":[],"source":["## some settings \n","FIGURE_SIZE = (20,10)\n","VISUALIZE = True        # change this if you want to visualize \n","                        # the plots while they are being generated \n","\n","## these are plotted with NetworkX on matplotlib\n","for net_type in FILE_DICT.keys():\n","    plot_graph_partition_original(\n","                                data        = FILE_DICT[net_type], \n","                                net_type    = net_type,\n","                                data_dir    = DATA_DIR,\n","                                figure_size = FIGURE_SIZE,\n","                                save_dir    = IMG_DIR,\n","                                visualize   = VISUALIZE\n","                                )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yKUncjOzH_3C"},"outputs":[],"source":["!pip3 install python-igraph==0.8.3\n","!apt install libcairo2-dev pkg-config python3-dev\n","!pip3 install python-igraph leidenalg cairocffi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O1Jv6b1sHwZJ"},"outputs":[],"source":["import igraph as ig"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AjJ-qcoTFJVF"},"outputs":[],"source":["\n","## Grid 6x6 \n","dd = './data/toy/grid-p-6x6.net'\n","save_dir = \"./imgs/toy/network_GRID_P_6x6_.png\"\n","g = ig.read(dd)\n","visual_style = {}\n","visual_style[\"edge_width\"] = 0.05 ## EDGE WIDTH\n","visual_style[\"vertex_size\"] = 3 ## SIZE OF THE NODEs\n","visual_style[\"bbox\"] = (300,300) ## SIZE OF GRAPH (MAINTAINS DPI)\n","visual_style[\"margin\"] = 10      ## MARGIN of the graph\n","ig.plot(g, save_dir, **visual_style)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-3fd8eayJzK8"},"outputs":[],"source":["\n","## AIRPORTS UW\n","## saving the AIRPORTS IMAGE \n","dy = \"./data/real/airports_UW.net\"\n","save_dir = \"./imgs/real/network_AIRPORTS_UW_.png\"\n","g = ig.read(dy)\n","visual_style = {}\n","visual_style[\"edge_width\"] = 0.05\n","visual_style[\"vertex_size\"] = 3\n","visual_style[\"bbox\"] = (720,480)\n","visual_style[\"margin\"] = 10\n","ig.plot(g, save_dir, **visual_style)"]},{"cell_type":"markdown","metadata":{"id":"s-OJanYgFJVH"},"source":["### Calculating Partitions for each graph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0mEXWXebFJVL"},"outputs":[],"source":["from src.helpers.partitions import make_best_partition\n","from src.helpers.metrics import calculate_metrics\n","from src.helpers.helpers import clean_community\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jBQeYamIFJVT"},"outputs":[],"source":["SCHEMA = {\n","                \"MODEL_TYPE\":None,\n","                \"FILE_NAME\":None,\n","                \"NUM_NODES\":None,\n","                \"PARTITION_ID\":None,\n","                \"METHOD\":None,\n","                \"NUM_PARTITIONS\":None,\n","                \"GEN_PARTITION\":None,\n","                \"NX_NVI\":None,\n","                \"NX_NMI\":None,\n","                \"NX_RAND_IDX\":None,\n","                \"IG_NVI\":None,\n","                \"IG_NMI\":None,\n","                \"IG_RAND_IDX\":None,\n","          \n","          \n","            }\n","\n","def make_schema(SCHEMA, update_vals):\n","    ### incoming vals are going to be the same as the schema \n","    out = dict(zip(SCHEMA.keys(), update_vals))\n","    return out"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import igraph as ig \n","def load_igraph(file_name):\n","  g = ig.read(file_name)\n","  g = g.simplify()\n","  return g\n","\n","def get_igraph_greedy(graph):\n","  ## try to use the same methods we used \n","  ## MODULARITY \n","  dendrogram = graph.community_fastgreedy()\n","  clusters = dendrogram.as_clustering()\n","  membership = clusters.membership\n","  ## dictionary \n","  d = dict(zip(graph.vs['name'],membership))\n","  return d.values()\n","\n","## LABEL PROPAGATION \n","def get_igraph_label_prop(graph):\n","  lp = graph.community_label_propagation()\n","  lp_mem = lp.membership\n","  ## dictionary\n","  dlp = dict(zip(graph.vs['name'],lp_mem))\n","  return dlp.values()\n","## GIRVAN-NEWMAN\n","def get_igraph_newmann(graph):\n","  gn = graph.community_leading_eigenvector()\n","  gn_mem = gn.membership\n","  ## dictionary\n","  dlp = dict(zip(graph.vs['name'],gn_mem))\n","  return dlp.values()\n","def get_igraph_metrics(ofn):\n","  g = load_igraph(ofn)\n","  greedy = get_igraph_greedy(g)\n","  label_prop = get_igraph_label_prop(g)\n","  newman = get_igraph_newmann(g)\n","  return (greedy, label_prop, newman)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zrbjDp-WFJVU"},"outputs":[],"source":["algorithms = [\"Garvin-Newman\",\"Greedy\",\"Label-Propagation\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MUkAgnrVFJVV"},"outputs":[],"source":["## make the above for loop into a function \n","def get_payload(data,idx,alg,num_nodes,SCHEMA,MODEL, ofn, p_id,algorithms,v,HAS_ORIG_PART,igraph_data,verbose=True):\n","    ## calculate the metrics\n","    nvi, nmi, rand_idx = calculate_metrics(data = data, community_alg=alg[0])\n","    ignvi, ignmi, igrand_idx = calculate_metrics(data = data, community_alg=igraph_data[idx])\n","    payload = make_schema(SCHEMA,\n","                            [MODEL, ofn,num_nodes, p_id,algorithms[idx],len(v),HAS_ORIG_PART, nvi, nmi, rand_idx,ignvi, ignmi, igrand_idx]\n","                            )\n","    ## if verbose \n","    if verbose:\n","        print(pd.DataFrame.from_records(payload, index=[0],columns=payload.keys()).to_markdown(),'\\n')\n","    \n","    return payload"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qnBft63pFJVW"},"outputs":[],"source":["from tqdm import tqdm\n","import pandas as pd\n","import time\n","import os\n","from src.helpers.partitions import calculate_partitions\n","## \n","VERBOSITY = True\n","\n","holder = []\n","for MODEL in [\"toy\",\"model\",\"real\"]:\n","  for k, v in FILE_DICT[MODEL].items():\n","    if \"airports\" in k:\n","      pass\n","    else: \n","      tic = time.time()\n","      ofn = f\"{DATA_DIR}/{MODEL}/{k}.net\"\n","      ## load the graph and position\n","      g, pos = load_graph_coords(ofn) ## loading\n","      ## load the igraph one\n","      num_nodes = len(g.nodes())\n","      metrics = calculate_partitions(g, pos) ## communities\n","      c_metrics = clean_community(metrics) ## cleaning\n","      toc = time.time()\n","      ## calculate the difference one ## original partition\n","      if len(v) == 0:\n","        data1 = make_best_partition(g)\n","        p_id = 1\n","        HAS_ORIG_PART = bool(False)\n","        ## draw the original plot \n","        fig, axs = plt.subplots(1,4,figsize=(40,12))\n","        axs = axs.ravel()\n","        nx.draw(g, pos=pos, node_color=data1, ax=axs[0])\n","        axs[0].set_title(\"Original Partition\")\n","        ## \n","        for idx, alg in enumerate(c_metrics):\n","          ig_data = get_igraph_metrics(ofn)\n","          payload = get_payload(data1,idx,alg,num_nodes,SCHEMA,MODEL, ofn, p_id,algorithms,v,HAS_ORIG_PART,ig_data,verbose=VERBOSITY)\n","          holder.append(payload)\n","          ## plot the partitions \n","          nx.draw(g, pos=pos, node_color=alg[0], ax=axs[idx+1])\n","          axs[idx+1].set_title(f\"Partition for {algorithms[idx]}\")\n","        plt.suptitle(f\"{MODEL}-{k}\")\n","        name_to_save = f\"./imgs/partitions/{MODEL}_{k}_{algorithms[idx]}.png\"\n","        plt.savefig(name_to_save,bbox_inches='tight')\n","        plt.show()\n","  \n","      elif len(v) ==1:\n","        p_id = 1\n","        data2 = read_clu(v[0])\n","        HAS_ORIG_PART = bool(True)\n","        fig, axs = plt.subplots(1,4,figsize=(40,12))\n","        axs = axs.ravel()\n","        nx.draw(g, pos=pos, node_color=data2, ax=axs[0])\n","        axs[0].set_title(\"Original Partition\")\n","        for idx2, alg2 in enumerate(c_metrics):\n","          ig_data = get_igraph_metrics(ofn)\n","          payload = get_payload(data2,idx2,alg2,num_nodes,SCHEMA,MODEL, ofn, p_id,algorithms,v,HAS_ORIG_PART,ig_data,verbose=VERBOSITY)\n","          holder.append(payload)\n","          nx.draw(g, pos=pos, node_color=alg2[0], ax=axs[idx2+1])\n","          axs[idx2+1].set_title(f\"Partition for {algorithms[idx2]}\")\n","        plt.suptitle(f\"{MODEL}-{k}\")\n","        name_to_save = f\"./imgs/partitions/{MODEL}_{k}_{algorithms[idx2]}.png\"\n","        plt.savefig(name_to_save,bbox_inches='tight')\n","        plt.show()\n","    \n","      if len(v) > 1: \n","        for idx3, part3 in enumerate(v):\n","          ## pid\n","          p_id = idx3 + 1\n","          data3 = read_clu(part3)\n","          HAS_ORIG_PART = bool(True)\n","          fig, axs = plt.subplots(1,4,figsize=(40,12))\n","          axs = axs.ravel()\n","          nx.draw(g, pos=pos, node_color=data3, ax=axs[0])\n","          axs[0].set_title(f\"Original Partition - {idx3+1}\")\n","          for nidx3,alg3 in enumerate(c_metrics):\n","            ig_data = get_igraph_metrics(ofn)\n","            payload = get_payload(data3,nidx3,alg3,num_nodes,SCHEMA,MODEL, ofn, p_id,algorithms,v,HAS_ORIG_PART,ig_data,verbose=VERBOSITY)\n","            holder.append(payload)\n","            nx.draw(g, pos=pos, node_color=alg3[0], ax=axs[nidx3+1])\n","            axs[nidx3+1].set_title(f\"Partition for {algorithms[nidx3]}\")\n","          plt.suptitle(f\"{MODEL}-{k} Partition: {idx3+1}\")\n","          name_to_save = f\"./imgs/partitions/{MODEL}_{k}_{algorithms[nidx3]}_{idx3+1}.png\"\n","          plt.savefig(name_to_save,bbox_inches='tight')\n","          plt.show()"]},{"cell_type":"markdown","metadata":{"id":"E1b-hYx_FJV-"},"source":["### iGraph Algorithms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s81jhzLDWc2r"},"outputs":[],"source":["## make the above for loop into a function \n","def get_payload(data,idx,alg,num_nodes,SCHEMA,MODEL, ofn, p_id,algorithms,v,HAS_ORIG_PART,igraph_data,verbose=True):\n","    ## calculate the metrics\n","    nvi, nmi, rand_idx = calculate_metrics(data = data, community_alg=list(alg))\n","    ignvi, ignmi, igrand_idx = calculate_metrics(data = data, community_alg=igraph_data[idx])\n","    payload = make_schema(SCHEMA,\n","                            [MODEL, ofn,num_nodes, p_id,algorithms[idx],len(v),HAS_ORIG_PART, nvi, nmi, rand_idx,ignvi, ignmi, igrand_idx]\n","                            )\n","    ## if verbose \n","    if verbose:\n","        print(pd.DataFrame.from_records(payload, index=[0],columns=payload.keys()).to_markdown(),'\\n')\n","    \n","    return payload"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w0FvLY_6RRyo"},"outputs":[],"source":["## repeat the same with another library to see if there is any difference. \n","hold1 = []\n","MODEL = 'real'\n","AIRPORT = \"./data/real/airports_UW.net\"\n","## load the graph and position\n","g = load_igraph(AIRPORT)\n","## load the igraph one\n","num_nodes = len(g.vs())\n","metrics = get_igraph_metrics(AIRPORT)\n","## make the best partition to compare\n","best_partition = g.community_multilevel()\n","members_best = best_partition.membership\n","##\n","v = [0]\n","HAS_ORIG_PART=False\n","for idx, alg in enumerate(metrics):\n","  print(len(members_best),len(alg))\n","  ig_data = get_igraph_metrics(AIRPORT)\n","  payload = get_payload(members_best,idx,alg,num_nodes,SCHEMA,MODEL, AIRPORT, 1,algorithms,v,HAS_ORIG_PART,ig_data,verbose=False)\n","  hold1.append(payload)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_CJDfdh4XQH-"},"outputs":[],"source":["## final DataFrame with all the data \n","df = pd.DataFrame(holder) ## initial run NetworkX & iGraph\n","dff = pd.DataFrame(hold1) ## second run with NetworkX & iGraph\n","dii = pd.concat([df,dff]) ## combining\n","dii.to_csv(f\"./data/model_metrics/all_models.csv\") ## final dataframe"]}],"metadata":{"colab":{"collapsed_sections":["S5hNC3P2FJU4","dxKpCs5DFJU-","4iQnWk-mFJVB","FltsXwxWFJVD","s-OJanYgFJVH","E1b-hYx_FJV-"],"name":"A3-Community_Detection_Main.ipynb","provenance":[]},"interpreter":{"hash":"ac6858c3dbc49267e902ff986705b591b9d7b57befff84fd7d814fe16c4a8e1f"},"kernelspec":{"display_name":"Python 3.8.5","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
