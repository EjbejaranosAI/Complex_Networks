{"cells":[{"cell_type":"markdown","metadata":{"id":"BxJ2GIdNFJUo"},"source":["## A3. Community detection"]},{"cell_type":"markdown","metadata":{"id":"S5hNC3P2FJU4"},"source":["### Imports & Settings"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Unable to locate an executable at \"/Library/Java/JavaVirtualMachines/jdk1.8.0_77.jdk/Contents/Home/bin/apt\" (-1)\n"]}],"source":["## get the community module \n","!pip3 install -qq python-igraph==0.8.3 ## Networks\n","!pip3 install -qq networkx python-louvain ## Networks\n","!apt install libcairo2-dev pkg-config python3-dev ## plotting \n","!pip3 install -qq leidenalg cairocffi ## plotting"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"NVNgAy_PFJU9"},"outputs":[{"name":"stdout","output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}],"source":["## autoreload \n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"dxKpCs5DFJU-"},"source":["### Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sdrF05FgFO_W"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kOs8R7mMFdWs"},"outputs":[],"source":["## change to the work dir \n","WORK_DIR = \"./drive/MyDrive/Cursos/3_Community_detection\"\n","import os; os.chdir(WORK_DIR)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"UkBTmQ19FJU_"},"outputs":[],"source":["## import libraries \n","import networkx as nx \n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"OVFZbZIvFJVA"},"outputs":[],"source":["## helper functions \n","from src.helpers.helpers import read_clu,load_graph_coords\n","from src.helpers.plotters import plot_graph_partition_original"]},{"cell_type":"markdown","metadata":{"id":"4iQnWk-mFJVB"},"source":["### Defining Paths & Variables"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"Q7OcKAbHFJVC"},"outputs":[],"source":["## helper functions\n","from src.helpers.config import config_dict,make_net_file_dict\n","## Setting the PATHS to the specific directories \n","DATA_DIR = './data'\n","IMG_DIR = './imgs'\n","## Loading the config dictionary \n","CONFIG = config_dict(dir=DATA_DIR)\n","## getting the net files & file dictionary\n","NET_FILES, FILE_DICT = make_net_file_dict(CONFIG)"]},{"cell_type":"markdown","metadata":{"id":"FltsXwxWFJVD"},"source":["### Plotting Original Graphs & Partitions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c9R9WGe0FJVE"},"outputs":[],"source":["## some settings \n","FIGURE_SIZE = (20,10)\n","VISUALIZE = True        # change this if you want to visualize \n","                        # the plots while they are being generated \n","\n","## these are plotted with NetworkX on matplotlib\n","for net_type in FILE_DICT.keys():\n","    plot_graph_partition_original(\n","                                data        = FILE_DICT[net_type], \n","                                net_type    = net_type,\n","                                data_dir    = DATA_DIR,\n","                                figure_size = FIGURE_SIZE,\n","                                save_dir    = IMG_DIR,\n","                                visualize   = VISUALIZE\n","                                )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yKUncjOzH_3C"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":12,"metadata":{"id":"O1Jv6b1sHwZJ"},"outputs":[],"source":["import igraph as ig"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AjJ-qcoTFJVF"},"outputs":[],"source":["\n","## Grid 6x6 \n","dd = './data/toy/grid-p-6x6.net'\n","save_dir = \"./imgs/toy/network_GRID_P_6x6_.png\"\n","g = ig.read(dd)\n","visual_style = {}\n","visual_style[\"edge_width\"] = 0.05 ## EDGE WIDTH\n","visual_style[\"vertex_size\"] = 3 ## SIZE OF THE NODEs\n","visual_style[\"bbox\"] = (300,300) ## SIZE OF GRAPH (MAINTAINS DPI)\n","visual_style[\"margin\"] = 10      ## MARGIN of the graph\n","ig.plot(g, save_dir, **visual_style)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-3fd8eayJzK8"},"outputs":[],"source":["\n","## AIRPORTS UW\n","## saving the AIRPORTS IMAGE \n","dy = \"./data/real/airports_UW.net\"\n","save_dir = \"./imgs/real/network_AIRPORTS_UW_.png\"\n","g = ig.read(dy)\n","visual_style = {}\n","visual_style[\"edge_width\"] = 0.05\n","visual_style[\"vertex_size\"] = 3\n","visual_style[\"bbox\"] = (720,480)\n","visual_style[\"margin\"] = 10\n","ig.plot(g, save_dir, **visual_style)"]},{"cell_type":"markdown","metadata":{"id":"s-OJanYgFJVH"},"source":["### Calculating Partitions for each graph"]},{"cell_type":"code","execution_count":104,"metadata":{"id":"0mEXWXebFJVL"},"outputs":[],"source":["from src.helpers.partitions import make_best_partition\n","from src.helpers.metrics import calculate_metrics\n","from src.helpers.helpers import clean_community\n"]},{"cell_type":"code","execution_count":105,"metadata":{"id":"jBQeYamIFJVT"},"outputs":[],"source":["SCHEMA = {\n","                \"MODEL_TYPE\":None,\n","                \"FILE_NAME\":None,\n","                \"NUM_NODES\":None,\n","                \"PARTITION_ID\":None,\n","                \"METHOD\":None,\n","                \"NUM_PARTITIONS\":None,\n","                \"GEN_PARTITION\":None,\n","                \"NX_NVI\":None,\n","                \"NX_NMI\":None,\n","                \"NX_RAND_IDX\":None,\n","                \"IG_NVI\":None,\n","                \"IG_NMI\":None,\n","                \"IG_RAND_IDX\":None,\n","                \"IG_MOD\":None,\n","                \"NX_MOD\":None,\n","          \n","            }\n","\n","def make_schema(SCHEMA, update_vals):\n","    ### incoming vals are going to be the same as the schema \n","    out = dict(zip(SCHEMA.keys(), update_vals))\n","    return out"]},{"cell_type":"code","execution_count":106,"metadata":{},"outputs":[],"source":["import igraph as ig \n","def load_igraph(file_name):\n","  g = ig.read(file_name)\n","  g = g.simplify()\n","  return g\n","\n","def get_igraph_greedy(graph):\n","  ## try to use the same methods we used \n","  ## MODULARITY \n","  dendrogram = graph.community_fastgreedy()\n","  clusters = dendrogram.as_clustering()\n","  membership = clusters.membership\n","  ## dictionary \n","  d = dict(zip(graph.vs['name'],membership))\n","  return d.values()\n","\n","## LABEL PROPAGATION \n","def get_igraph_label_prop(graph):\n","  lp = graph.community_label_propagation()\n","  lp_mem = lp.membership\n","  ## dictionary\n","  dlp = dict(zip(graph.vs['name'],lp_mem))\n","  return dlp.values()\n","## GIRVAN-NEWMAN\n","def get_igraph_newmann(graph):\n","  gn = graph.community_leading_eigenvector()\n","  gn_mem = gn.membership\n","  ## dictionary\n","  dlp = dict(zip(graph.vs['name'],gn_mem))\n","  return dlp.values()\n","def get_igraph_metrics(ofn):\n","  g = load_igraph(ofn)\n","  greedy = get_igraph_greedy(g)\n","  label_prop = get_igraph_label_prop(g)\n","  newman = get_igraph_newmann(g)\n","  return (greedy, label_prop, newman)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":107,"metadata":{},"outputs":[{"data":{"text/plain":["0.6087328970850684"]},"execution_count":107,"metadata":{},"output_type":"execute_result"}],"source":["part = \"./data/model/rb125-1.clu\"\n","fn = \"./data/model/rb125.net\"\n","g = load_igraph(fn)\n","p = read_clu(part)\n","## compare modularity \n","mod = g.modularity(p)\n","\n","gr = get_igraph_greedy(g)\n","g.modularity(gr)"]},{"cell_type":"code","execution_count":108,"metadata":{},"outputs":[{"data":{"text/plain":["0.5180189115916156"]},"execution_count":108,"metadata":{},"output_type":"execute_result"}],"source":["from src.helpers.community import NetworkXCommunityAlgs\n","from src.helpers.partitions import calculate_partitions\n","## nx \n","g, pos = load_graph_coords(fn)\n","##\n","metrics = calculate_partitions(g, pos)\n","gn = metrics[0][0]\n","## calculate modularity \n","## girvan \n","ca1 = NetworkXCommunityAlgs(g, method='girvan_newman',layout=pos, verbosity=False)\n","comm1, ca1_nc = ca1.algorithm\n","##greedy (modularity):\n","ca2 = NetworkXCommunityAlgs(g, method='greedy',layout=pos, verbosity=False)\n","comm2, ca2_nc = ca2.algorithm\n","## Label Propagation\n","ca3 = NetworkXCommunityAlgs(g, method='label_prop',layout=pos, verbosity=False)\n","comm3, ca3_nc = ca3.algorithm\n","## compare \n","nx.algorithms.community.modularity(g,comm3)"]},{"cell_type":"code","execution_count":109,"metadata":{"id":"zrbjDp-WFJVU"},"outputs":[],"source":["algorithms = [\"Garvin-Newman\",\"Greedy\",\"Label-Propagation\"]\n"]},{"cell_type":"code","execution_count":143,"metadata":{"id":"MUkAgnrVFJVV"},"outputs":[],"source":["## make the above for loop into a function \n","def get_payload(graph,community_idxs, data,idx,alg,num_nodes,SCHEMA,MODEL, ofn, p_id,algorithms,v,HAS_ORIG_PART,igraph_data,verbose=True):\n","    ## calculate the metrics\n","    nvi, nmi, rand_idx,nx_mod = calculate_metrics(graph=graph, data = data, community_alg=alg[0], community_idx=community_idxs[idx])\n","    ignvi, ignmi, igrand_idx,ig_mod = calculate_metrics(graph=graph,\n","                                                        data = data, \n","                                                        community_alg=igraph_data[idx],\n","                                                        community_idx=community_idxs[idx])\n","    payload = make_schema(\n","                            SCHEMA,\n","                            [\n","                                MODEL,\n","                                ofn,num_nodes,\n","                                p_id,\n","                                algorithms[idx],\n","                                len(v),\n","                                HAS_ORIG_PART,\n","                                nvi, nmi, rand_idx,\n","                                ignvi, ignmi, igrand_idx,\n","                                ig_mod, nx_mod\n","                             ]\n","                            )\n","    ## if verbose\n","    if verbose:\n","        print(pd.DataFrame.from_records(payload, index=[0],columns=payload.keys()).to_markdown(),'\\n')\n","    \n","    return payload"]},{"cell_type":"code","execution_count":144,"metadata":{},"outputs":[],"source":["from src.helpers.partitions import calculate_partitions\n","part = \"./data/model/rb125-1.clu\"\n","fn = \"./data/model/rb125.net\"\n","g = load_igraph(fn)\n","p = read_clu(part)\n","## compare modularity \n","mod = g.modularity(p)\n","gr = get_igraph_greedy(g)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qnBft63pFJVW"},"outputs":[],"source":["from tqdm import tqdm\n","import pandas as pd\n","import time\n","import os\n","from src.helpers.partitions import calculate_partitions\n","## \n","VERBOSITY = True\n","\n","holder = []\n","for MODEL in [\"toy\",\"model\",\"real\"]:\n","  for k, v in FILE_DICT[MODEL].items():\n","    if \"airports\" in k:\n","      pass\n","    else: \n","      tic = time.time()\n","      ofn = f\"{DATA_DIR}/{MODEL}/{k}.net\"\n","      ## load the graph and position\n","      g, pos = load_graph_coords(ofn) ## loading\n","      ## load the igraph one\n","      num_nodes = len(g.nodes())\n","      metrics, community_idxs = calculate_partitions(g, pos) ## communities\n","      c_metrics = clean_community(metrics) ## cleaning\n","      toc = time.time()\n","      ## calculate the difference one ## original partition\n","      if len(v) == 0:\n","        data1 = make_best_partition(g)\n","        p_id = 1\n","        HAS_ORIG_PART = bool(False)\n","        ## draw the original plot \n","        #fig, axs = plt.subplots(1,4,figsize=(40,12))\n","        #axs = axs.ravel()\n","        #nx.draw(g, pos=pos, node_color=data1, ax=axs[0])\n","        #axs[0].set_title(\"Original Partition\")\n","        ## \n","        for idx, alg in enumerate(c_metrics):\n","          ig_data = get_igraph_metrics(ofn)\n","          payload = get_payload(g,community_idxs, data1,idx,alg,num_nodes,SCHEMA,MODEL, ofn, p_id,algorithms,v,HAS_ORIG_PART,ig_data,verbose=VERBOSITY)\n","          holder.append(payload)\n","          ## plot the partitions \n","        #   nx.draw(g, pos=pos, node_color=alg[0], ax=axs[idx+1])\n","        #   axs[idx+1].set_title(f\"Partition for {algorithms[idx]}\")\n","        # plt.suptitle(f\"{MODEL}-{k}\")\n","        # name_to_save = f\"./imgs/partitions/{MODEL}_{k}_{algorithms[idx]}.png\"\n","        # plt.savefig(name_to_save,bbox_inches='tight')\n","        # plt.show()\n","  \n","      elif len(v) ==1:\n","        p_id = 1\n","        data2 = read_clu(v[0])\n","        HAS_ORIG_PART = bool(True)\n","        # fig, axs = plt.subplots(1,4,figsize=(40,12))\n","        # axs = axs.ravel()\n","        # nx.draw(g, pos=pos, node_color=data2, ax=axs[0])\n","        # axs[0].set_title(\"Original Partition\")\n","        for idx2, alg2 in enumerate(c_metrics):\n","          ig_data = get_igraph_metrics(ofn)\n","          payload = get_payload(g,community_idxs,data2,idx2,alg2,num_nodes,SCHEMA,MODEL, ofn, p_id,algorithms,v,HAS_ORIG_PART,ig_data,verbose=VERBOSITY)\n","          holder.append(payload)\n","        #   nx.draw(g, pos=pos, node_color=alg2[0], ax=axs[idx2+1])\n","        #   axs[idx2+1].set_title(f\"Partition for {algorithms[idx2]}\")\n","        # plt.suptitle(f\"{MODEL}-{k}\")\n","        # name_to_save = f\"./imgs/partitions/{MODEL}_{k}_{algorithms[idx2]}.png\"\n","        # plt.savefig(name_to_save,bbox_inches='tight')\n","        # plt.show()\n","    \n","      if len(v) > 1: \n","        for idx3, part3 in enumerate(v):\n","          ## pid\n","          p_id = idx3 + 1\n","          data3 = read_clu(part3)\n","          HAS_ORIG_PART = bool(True)\n","          # fig, axs = plt.subplots(1,4,figsize=(40,12))\n","          # # axs = axs.ravel()\n","          # nx.draw(g, pos=pos, node_color=data3, ax=axs[0])\n","          # axs[0].set_title(f\"Original Partition - {idx3+1}\")\n","          for nidx3,alg3 in enumerate(c_metrics):\n","            ig_data = get_igraph_metrics(ofn)\n","            payload = get_payload(g,community_idxs,data3,nidx3,alg3,num_nodes,SCHEMA,MODEL, ofn, p_id,algorithms,v,HAS_ORIG_PART,ig_data,verbose=VERBOSITY)\n","            holder.append(payload)\n","          #   nx.draw(g, pos=pos, node_color=alg3[0], ax=axs[nidx3+1])\n","          #   axs[nidx3+1].set_title(f\"Partition for {algorithms[nidx3]}\")\n","          # plt.suptitle(f\"{MODEL}-{k} Partition: {idx3+1}\")\n","          # name_to_save = f\"./imgs/partitions/{MODEL}_{k}_{algorithms[nidx3]}_{idx3+1}.png\"\n","          # plt.savefig(name_to_save,bbox_inches='tight')\n","          # plt.show()\n","## save the data \n","df = pd.DataFrame(holder)\n","df.to_csv(f\"./data/model_metrics/{MODEL}.csv\") ## final da"]},{"cell_type":"code","execution_count":149,"metadata":{},"outputs":[{"data":{"text/plain":["{'MODEL_TYPE': 'toy',\n"," 'FILE_NAME': './data/toy/graph3+1+3.net',\n"," 'NUM_NODES': 7,\n"," 'PARTITION_ID': 1,\n"," 'METHOD': 'Garvin-Newman',\n"," 'NUM_PARTITIONS': 1,\n"," 'GEN_PARTITION': True,\n"," 'NX_NVI': 0.16513319924334835,\n"," 'NX_NMI': 0.8095401960023787,\n"," 'NX_RAND_IDX': 0.857142857142857,\n"," 'IG_NVI': 0.16513319924334835,\n"," 'IG_NMI': 0.8095401960023787,\n"," 'IG_RAND_IDX': 0.857142857142857,\n"," 'IG_MOD': 0.3671875,\n"," 'NX_MOD': 0.3671875}"]},"execution_count":149,"metadata":{},"output_type":"execute_result"}],"source":["holder[0]"]},{"cell_type":"code","execution_count":153,"metadata":{},"outputs":[],"source":["### compare modularity quickly \n","toy_df = pd.DataFrame([x for x in holder if x[\"MODEL_TYPE\"] == \"toy\"])\n","model_df = pd.DataFrame([x for x in holder if x[\"MODEL_TYPE\"] == \"model\"])\n","real_df = pd.DataFrame([x for x in holder if x[\"MODEL_TYPE\"] == \"real\"])\n","## save them all \n","toy_df.to_csv(f\"./data/model_metrics/toy.csv\")\n","model_df.to_csv(f\"./data/model_metrics/model.csv\")\n","real_df.to_csv(f\"./data/model_metrics/real.csv\")"]},{"cell_type":"markdown","metadata":{"id":"E1b-hYx_FJV-"},"source":["### iGraph Algorithms"]},{"cell_type":"code","execution_count":154,"metadata":{"id":"s81jhzLDWc2r"},"outputs":[],"source":["## make the above for loop into a function\n","def get_payload(g,data,idx,alg,num_nodes,SCHEMA,MODEL, ofn, p_id,algorithms,v,HAS_ORIG_PART,igraph_data,verbose=True):\n","    ## calculate the metrics\n","    nvi, nmi, rand_idx,m1= calculate_metrics(data = data, community_alg=list(alg),graph=g,igraph_data=igraph_data,community_idx=idx)\n","    ignvi, ignmi, igrand_idx,m2 = calculate_metrics(data = data, community_alg=igraph_data[idx],graph=g,igraph_data=igraph_data,community_idx=idx)\n","    payload = make_schema(SCHEMA,\n","                            [MODEL, ofn,num_nodes, p_id,algorithms[idx],len(v),HAS_ORIG_PART, nvi, nmi, rand_idx,ignvi, ignmi, igrand_idx,m2,m1]\n","                            )\n","    ## if verbose \n","    if verbose:\n","        print(pd.DataFrame.from_records(payload, index=[0],columns=payload.keys()).to_markdown(),'\\n')\n","    \n","    return payload"]},{"cell_type":"code","execution_count":156,"metadata":{"id":"w0FvLY_6RRyo"},"outputs":[{"name":"stdout","output_type":"stream","text":["3618 3618\n"]},{"ename":"TypeError","evalue":"get_payload() missing 1 required positional argument: 'igraph_data'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/var/folders/bd/f5z4cc193xgdxq1yr1xpflmm0000gn/T/ipykernel_3844/2857255327.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmembers_best\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mig_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_igraph_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAIRPORT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   payload = get_payload(g = g,\n\u001b[0m\u001b[1;32m     20\u001b[0m                         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmembers_best\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: get_payload() missing 1 required positional argument: 'igraph_data'"]}],"source":["## repeat the same with another library to see if there is any difference. \n","hold1 = []\n","MODEL = 'real'\n","AIRPORT = \"./data/real/airports_UW.net\"\n","## load the graph and position\n","g = load_igraph(AIRPORT)\n","## load the igraph one\n","num_nodes = len(g.vs())\n","metrics = get_igraph_metrics(AIRPORT)\n","## make the best partition to compare\n","best_partition = g.community_multilevel()\n","members_best = best_partition.membership\n","##\n","v = [0]\n","HAS_ORIG_PART=False\n","for idx, alg in enumerate(metrics):\n","  print(len(members_best),len(alg))\n","  ig_data = get_igraph_metrics(AIRPORT)\n","  payload = get_payload(g = g,\n","                        data = members_best,\n","                        idx = idx,\n","                        alg = alg,\n","                        num_nodes = num_nodes,\n","                        SCHEMA = SCHEMA,\n","                        MODEL = MODEL, \n","                        ofn = AIRPORT,\n","                        p_id = 1,\n","                        algorithms = algorithms,\n","                        v = v,\n","                        HAS_ORIG_PART=HAS_ORIG_PART,\n","                        verbose=False)\n","  hold1.append(payload)"]},{"cell_type":"code","execution_count":101,"metadata":{"id":"_CJDfdh4XQH-"},"outputs":[],"source":["## final DataFrame with all the data \n","df = pd.DataFrame(holder) ## initial run NetworkX & iGraph\n","dff = pd.DataFrame(hold1) ## second run with NetworkX & iGraph\n","dii = pd.concat([df,dff]) ## combining\n","dii.to_csv(f\"./data/model_metrics/all_models.csv\") ## final dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["S5hNC3P2FJU4","dxKpCs5DFJU-","4iQnWk-mFJVB","FltsXwxWFJVD","s-OJanYgFJVH","E1b-hYx_FJV-"],"name":"A3-Community_Detection_Main.ipynb","provenance":[]},"interpreter":{"hash":"ac6858c3dbc49267e902ff986705b591b9d7b57befff84fd7d814fe16c4a8e1f"},"kernelspec":{"display_name":"Python 3.8.5","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
